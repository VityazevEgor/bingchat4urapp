# LLMapi4free
LLMapi4free - это сервис, предоставляющий унифицированный доступ к различным LLM провайдерам через API. Сервис работает путем автоматизации действий в браузере, что позволяет получить бесплатный доступ к различным языковым моделям в виде API для ваших приложений.

[Демонстрация работы (старая версия)](https://youtu.be/lHJaL333qAE)

## Как запустить (Linux)?
1. Скачать OpenJDK минимум 17-ой версии `sudo apt install openjdk-17-jdk`
2. Установить xdotool `sudo apt install xdotool`
3. Установить браузер chrome
4. Скачать и запустить .jar файл из раздела "Release": `java -jar bingchat4urapp_server-0.0.1-SNAPSHOT.jar` 
5. Приложение будет запущено на порту 8080.

>Если вы хотите запустить это приложение на сервере, то вам **обязательно** надо развернуть на нём VNC сервер с графическим окружением и менджером окон X11

## Поддержка прокси
Если вы хотите использовать прокси-сервер, вам необходимо передать адрес прокси-сервера в качестве параметра в файл .jar. Обратите внимание, что поддерживаются только прокси-серверы SOCKS5 **без авторизации**. Например, вы можете передать прокси-сервер приложению через консоль следующим образом:

```bash
java -jar bingchat4urapp_server-0.0.1-SNAPSHOT.jar --proxy 127.0.0.1:2080
```

# Как использовать?

## Принцип работы

Сервер работает по асинхронному принципу с использованием задач:

1. Клиент создаёт задачу (авторизация, отправка промпта и т.д.) через соответствующий endpoint
2. Сервер возвращает ID созданной задачи
3. Клиент периодически опрашивает endpoint `/get/{id}` для получения статуса задачи, пока она не будет завершена (`isFinished = true`)

## Веб-интерфейс
Вам также доступен веб-интерфейс по пути `127.0.0.1:8080/` который позволит вам проверить работу приложения и разобраться в его работу
![Main page](images/webInterface.png "Main page")
![Asnwer page](images/webInterface2.png "Answer page")
![Providers page](images/webInterface3.png "Providers page")

## API Base URL
```
/api
```

## API Endpoints

### Аутентификация
#### Создание задачи аутентификации
>**Важно:** авторизация в Copilot происходит по логину и паролю от вашего Microsoft аккаунта. На вашем аккаунте должна быть выключен двухфакторная авторизация.

>**Важно:** авторизация в OpenAI(ChatGPT) происходит используя Google аккаунт. Вы должны самостоятельно войти в свой Google аккаунт в окне браузера, которое открывается при запуске сервера, и только потом использовать этот endpoint для создания задачи на авторизацию в OpenAI, передавая в качестве логина и пароля любые строки.
```http
POST /auth
```

**Request Body:**
```json
{
    "login": "string",
    "password": "string",
    "provider": "enum(LLMproviders)"
}
```

**Validation Rules:**
- `login`: 6-50 символов
- `password`: минимум 8 символов, максимум 50
- `provider`: одно из значений enum LLMproviders

**Response:**
- `201 Created`: ID созданной задачи (целое число)
```json
42
```
- `400 Bad Request`: ошибка валидации
- `500 Internal Server Error`: внутренняя ошибка сервера

### Управление чатом
#### Создание нового чата
```http
POST /createchat
```

**Response:**
- `201 Created`: ID созданной задачи на открытие нового чата
```json
43
```
- `500 Internal Server Error`: внутренняя ошибка при создании задачи

#### Отправка промпта
```http
POST /sendpromt
```

**Request Body:**
```json
{
    "promt": "string",
    "timeOutForAnswer": "integer"
}
```

**Validation Rules:**
- `promt`: 4-4000 символов
- `timeOutForAnswer`: 30-300 секунд

**Response:**
- `201 Created`: ID созданной задачи
```json
44
```
- `400 Bad Request`: ошибка валидации
- `500 Internal Server Error`: внутренняя ошибка на стороне сервера

### Управление провайдерами
#### Получение информации о доступных провайдерах
```http
GET /getProvidersInfo
```

**Response:**
- `200 OK`: список доступных LLM провайдеров
```json
[
    {
        "provider": "Copilot", // enum LLMproviders
        "chat": {
            "Copilot": "copilot"
        },
        "gotError": false, // была ли ошибка при использовании этого провайдера
        "authDone": true, // была ли выполнена авторизация
        "authRequired": true, // обязательна ли авторизация
        "lastAnswer": "Последний ответ от модели"
    },
    {
        "provider": "OpenAI",
        "chat": {
            "OpenAI": "openAI"
        },
        "gotError": false,
        "authDone": false,
        "authRequired": true,
        "lastAnswer": ""
    }
]
```

#### Установка предпочтительного провайдера
С помощью данного endpoint вы можете выбрать от какого провайдера вы предпочитаете получить ответ.
```http
POST /setPreferedProvider
```

**Request Body:**
```json
{
    "provider": "enum(LLMproviders)"
}
```

**Response:**
- `200 OK`: "Done!"
- `400 Bad Request`: ошибка валидации
- `500 Internal Server Error`: Внутренняя ошибка сервера

#### Получение текущего рабочего LLM
Возращает информацию о провайдере, который будет использоваться для следующей обработки промта.
```http
GET /getWorkingLLM
```

**Response:**
- `200 OK`: информация о текущем рабочем LLM провайдере, который используется программой для обработки промтов
```json
{
    "provider": "Copilot",
    "chat": {
        "type": "Copilot" // игнорируйте это поле
    },
    "gotError": false,
    "authDone": true,
    "authRequired": true,
    "lastAnswer": "Последний ответ от модели"
}
```

### Управление задачами
#### Получение статуса задачи
```http
GET /get/{id}
```

**Parameters:**
- `id`: ID задачи (integer)

**Response:**
- `200 OK`: информация о задаче
```json
{
    "id": 42,
    "type": 1,
    "data": {
        "param1": "value1",
        "param2": "value2"
    },
    "isFinished": true,
    "gotError": false,
    "result": "Текстовый результат выполнения задачи",
    "htmlResult": "<div>HTML результат выполнения задачи</div>",
    "imageResult": "имя_файла_изображения.png"
}
```
- `404 Not Found`: задача не найдена

### Системные endpoints
#### Завершение работы сервера
```http
GET /exit
```

**Response:**
- `200 OK`: "Server will be down in few seconds"

## Типы задач
- `type = 0`: Системная задача завершения работы
- `type = 1`: Задача аутентификации
- `type = 2`: Задача отправки промпта
- `type = 3`: Задача создания чата

## Формат ответов от LLM
При получении ответа от языковой модели, сервер всегда возвращает три поля:
- `result`: чистый текстовый ответ
- `htmlResult`: ответ в формате HTML с форматированием
- `imageResult`: имя файла изображения, скриншота ответа от модели

В случае возникновения ошибки:
- `gotError`: становится `true`
- `result`: содержит описание ошибки
- `isFinished`: становится `true`, указывая на завершение задачи с ошибкой

## Коды ответов

- `200 OK`: Успешное выполнение запроса
- `201 Created`: Успешное создание ресурса
- `400 Bad Request`: Ошибка в запросе (невалидные данные)
- `404 Not Found`: Запрашиваемый ресурс не найден
- `500 Internal Server Error`: Внутренняя ошибка сервера

## Примечания

- Все запросы, требующие тела, должны иметь Content-Type: application/json
- Таймаут ответа для промптов ограничен диапазоном 30-300 секунд
- При ошибках валидации сервер вернёт список конкретных ошибок валидации
- ID задач являются целыми числами и уникальны в рамках системы
- Все задачи выполняются асинхронно, клиент должен периодически проверять статус задачи
- Поля result, htmlResult и imageResult присутствуют в ответе всегда, даже если они пустые